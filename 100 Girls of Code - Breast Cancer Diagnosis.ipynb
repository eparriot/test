{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "\n",
    "############    In this exercise, we will be predicting whether or not a patient has breast cancer.        ####################\n",
    "############   The data is from the University of Wisconsin and contains attributes, or characteristics,   ####################\n",
    "############   about groups of cells that doctors had to determine were cancerous or not.                  ####################\n",
    "############   We will be using SUPERVISED machine learning techniques to label each group of cells either ####################\n",
    "############   cancer (\"malignant\") or not cancer (\"benign\"). This is called a classification problem.     ####################\n",
    "\n",
    "######   The data can be found here: http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29   #######\n",
    "######   The repository that provides the data is cited below:\n",
    "# Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.#\n",
    "# Template for this exercise can be found here: https://towardsdatascience.com/building-a-simple-machine-learning-model-on-breast-cancer-data-eca4b3b99fa3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, we import the libraries we will be needing to run our code:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Next, we read the dataset into pandas. Pandas is where your data lives in this notebook. This \"house\" for your data\n",
    "# looks like a table and is called a \"DataFrame\".\n",
    "# We want to work on that cancer dataset from the University of Wisconsin. This data is stored in a CSV file. \n",
    "# Pandas will extract the data from that CSV into a DataFrame (like a table).\n",
    "\n",
    "\n",
    "# Pandas is denoted here by \"pd\".\n",
    "\n",
    "dataset = pd.read_csv('wisconsin_breastcancer_dataset_UseThis.csv')  # Now 'dataset' is a pandas dataframe of our data.\n",
    "\n",
    "\n",
    "# Third, what does our data look like? The command '.head()' let's us see a specified amount of rows. \n",
    "# Tell '.head' how many rows you want to see by inputing a number into the paratheneses (), like this: .head(6)\n",
    "\n",
    "dataset.head(#enter how many rows you want to see here, make sure it's at least 5#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that you can't see all the column names above? \n",
    "# Type the command \"list()\" to see all the column names in the dataset.\n",
    "\n",
    "# Now you try:\n",
    "\n",
    "list(#insert name of your pandas dataframe#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing we want to do after loading the data into pandas is to make sure ALL the data was loaded. \n",
    "# To do this, we check the size of the data (how many rows and columns) and make sure this matches the number of \n",
    "# rows and columns in our csv. You don't have to check the size of the csv yourself, below we've provided the numbers \n",
    "# that you should see. \n",
    "\n",
    "print(\"Cancer data set dimensions : {}\".format(dataset.shape))\n",
    "#You should see -> Cancer data set dimensions : (569, 32)\n",
    "\n",
    "\n",
    "# Do you know what these 2 numbers mean? \n",
    "# Type your answer here:                                                              #\n",
    "\n",
    "# If you don't know, no worries. :) You can take a guess and we'll go over it at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to make sure all the data is the right type. This is important because if a column comes in as a string but \n",
    "# we really need it to be an integer, it can mess up our machine learning model and we'll get an error.\n",
    "\n",
    "# This command shows us the data types of each column\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘Diagnosis’ is the column which we are going to predict.\n",
    "# It says if the group of cells is M = malignant or B = benign. \n",
    "# So how many people have malignant cells and how many don't?\n",
    "\n",
    "\n",
    "dataset['Diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look above - We can identify that out of the 569 persons, 357 are labeled as B (benign) and 212 as M (malignant). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For what percent of the data is the cancer malignant?\n",
    "\n",
    "# Enter code to calculate the percent malignant cancer out of all the data here: type answer here                         #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data:\n",
    "\n",
    "# Machine learning packages need you to do something about the null values before you can run them. \n",
    "# Let's check and see if there are nulls in our data. \n",
    "\n",
    "dataset.isnull().sum()\n",
    "dataset.isna().sum()\n",
    "\n",
    "# Doesn't look like there are any nulls! If there were, we would need to either delete that row or fill in that value, likely \n",
    "# with the mean of the column (if numeric). Ask Emily or Shweta to talk more about imputation, another way to fill in nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to separate our data into the target (what we want to predict, \"malignant\" or \"benign\" - the \"Diagnosis\" column) \n",
    "#and the data, or attributesthat are going to help us predict this target (all the other columns besides the \"Diagnosis\" column).\n",
    "\n",
    "X = dataset.iloc[:, 2:31].values # all the other columns, or attributes\n",
    "Y = dataset.iloc[:, 1].values # the target column for whcih we're trying to predict the classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what X looks like. Run this to find out.\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's see what Y looks like. Run this to find out.\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorical data values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Emily will explain this part. Let her know when you've reached here.\n",
    "# The code below is complete, you just need to run it.\n",
    "\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y\n",
    "# 1 means the diagnosis is malignant and 0 means benign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into the Training set and Test set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Emily will explain this part. Let her know when you've reached here.\n",
    "# The code below is almost complete, you just need to put in the test size, in the form of a decimal (ex. \"0.25\").\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = #enter test size here#, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to see the training data for the attributes.\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to see the test data for the attributes.\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to see the training data for the target, aka the label of \"malignant\" or \"benign\" that has been one-hot encoded.\n",
    "\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to see the test data for the target, aka the label of \"malignant\" or \"benign\" that has been one-hot encoded.\n",
    "\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Emily will explain this part. Let her know when you've reached here.\n",
    "# The code below is almost complete, you just need to fill in the data for X (train & test).\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(# enter numerical training data here #)\n",
    "X_test = sc.transform(# enter numerical test data here #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression Algorithm to the Training Set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Emily will explain this part. Let her know when you've reached here.\n",
    "# The code below is almost complete, you just need to fill in the training data.\n",
    "\n",
    "\n",
    "classifier_logr = LogisticRegression(random_state = 0)\n",
    "classifier_logr.fit(#enter numerical training data here# , #enter target training data here#)\n",
    "\n",
    "Y_pred_logr = classifier_logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you guys remember what Shweta was saying about the confusion matrix, back when we were doing the 'dog or cookie?' example?\n",
    "# Raise your hand if you want to explain the concept again, just to give us all a refresher. \n",
    "# No worries if you don't totally remember, we're going to go over it again here - just let Emily know you've reached this part.\n",
    "\n",
    "\n",
    "# Now that we've gone over confusion matrices again, run the below code and type out in comments what each of the numbers mean.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm_logr = confusion_matrix(Y_test, Y_pred_logr)\n",
    "\n",
    "cm_logr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do each of the 4 numbers in the confusion matrix above represent? Write your answers below.\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Emily will explain this part. Let her know when you've reached here.\n",
    "# The code below is almost complete, you just need to fill in the training data.\n",
    "\n",
    "\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier_knn.fit(#enter numerical training data here# , #enter target training data here#)\n",
    "\n",
    "Y_pred_knn = classifier_knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Now that we've gone over confusion matrices again, run the below code and type out in comments what each of the numbers mean.\n",
    "\n",
    "cm_knn = confusion_matrix(Y_test, Y_pred_knn)\n",
    "\n",
    "cm_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do each of the 4 numbers in the confusion matrix above represent? Write your answers below.\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Emily will explain this part. Let her know when you've reached here.\n",
    "# The code below is almost complete, you just need to fill in the training data.\n",
    "\n",
    "\n",
    "classifier_dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier_dt.fit(#enter numerical training data here# , #enter target training data here#)\n",
    "\n",
    "Y_pred_dt = classifier_dt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Now that we've gone over confusion matrices again, run the below code and type out in comments what each of the numbers mean.\n",
    "\n",
    "cm_dt = confusion_matrix(Y_test, Y_pred_dt)\n",
    "\n",
    "cm_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do each of the 4 numbers in the confusion matrix above represent? Write your answers below.\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
